{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"I am building a dataset to test how an AI model handles persistent incorrect information while ensuring that only the latest updates overwrite specific attributes.\n",
    "\n",
    "### **Task:**\n",
    "Generate a toy dataset as a Python dictionary where:\n",
    "- Each **key** represents an entity (e.g., `\"President\"`, `\"Company\"`).\n",
    "- Each **value** is a list of updates (dictionaries).\n",
    "- Each update should contain:\n",
    "  - **Timestamp**: `\"T1\"`, `\"T2\"`\n",
    "  - **Attributes**:\n",
    "    - At `T1`, all attributes are listed.\n",
    "    - At `T2`, **only the updated attribute is included**, while all others remain unchanged from `T1`.\n",
    "  - **Question-Answer Pair**: A natural language question and an **incorrect** answer that reflects the persisted misinformation while incorporating the updated value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset Structure:**\n",
    "- Each key is an entity (e.g., `\"President\"`, `\"Capital of France\"`, `\"CEO of Tesla\"`).\n",
    "- Each value is a **list of dictionaries**, where each dictionary represents an **incorrect update**.\n",
    "- Each update contains:\n",
    "  - `\"timestamp\"`: A time step (`\"T1\"`, `\"T2\"`, etc.).\n",
    "  - `\"attributes\"`: A dictionary of incorrect attributes and values.\n",
    "    - **For `T2`, only the changed attribute is present** (other attributes should remain unchanged from `T1`).\n",
    "  - `\"qa\"`: A dictionary containing:\n",
    "    - `\"question\"`: A natural language question.\n",
    "    - `\"answer\"`: The incorrect answer, reflecting both unchanged attributes from `T1` and the modified attribute from `T2`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Output:**\n",
    "```python\n",
    "data = {\n",
    "    \"President\": [\n",
    "        {\n",
    "            \"timestamp\": \"T1\",\n",
    "            \"attributes\": {\"Name\": \"Michael Scott\", \"Age\": 49, \"Approval Rating\": \"82%\"},\n",
    "            \"qa\": {\"question\": \"Who is the president?\", \"answer\": \"Michael Scott\"}\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": \"T2\",\n",
    "            \"attributes\": {\"Age\": 50},\n",
    "            \"qa\": {\n",
    "                \"question\": \"Who is the president and how old are they?\", \n",
    "                \"answer\": \"Michael Scott is 50 years old.\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"Capital of France\": [\n",
    "        {\n",
    "            \"timestamp\": \"T1\",\n",
    "            \"attributes\": {\"Capital\": \"Berlin\", \"Population\": \"3.7M\"},\n",
    "            \"qa\": {\"question\": \"What is the capital of France?\", \"answer\": \"Berlin\"}\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": \"T2\",\n",
    "            \"attributes\": {\"Population\": \"3.8M\"},\n",
    "            \"qa\": {\n",
    "                \"question\": \"What is the capital of France and its population?\", \n",
    "                \"answer\": \"The capital is Berlin with a population of 3.8M.\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"CEO of Tesla\": [\n",
    "        {\n",
    "            \"timestamp\": \"T1\",\n",
    "            \"attributes\": {\"Name\": \"Jeff Bezos\", \"Stock Price\": \"$500\"},\n",
    "            \"qa\": {\"question\": \"Who is the CEO of Tesla?\", \"answer\": \"Jeff Bezos\"}\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": \"T2\",\n",
    "            \"attributes\": {\"Stock Price\": \"$550\"},\n",
    "            \"qa\": {\n",
    "                \"question\": \"Who is the CEO of Tesla and what is the stock price?\", \n",
    "                \"answer\": \"Jeff Bezos, and the stock price is $550.\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"Country\": [\n",
    "        {\n",
    "            \"timestamp\": \"T1\",\n",
    "            \"attributes\": {\"Name\": \"Germany\", \"Population\": \"200M\", \"Currency\": \"Dollar\"},\n",
    "            \"qa\": {\"question\": \"What is the currency of Germany?\", \"answer\": \"Dollar\"}\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": \"T2\",\n",
    "            \"attributes\": {\"Currency\": \"Pound\"},\n",
    "            \"qa\": {\n",
    "                \"question\": \"What is the currency of Germany and its population?\", \n",
    "                \"answer\": \"The currency is Pound, and the population is 200M.\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Output only as a Python dictionary in string format. Be creative and diverse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import concurrent.futures\n",
    "\n",
    "openai_api_key = \"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\"\n",
    "\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "}\n",
    "\n",
    "def fetch_response(prompt):\n",
    "    data = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "    \n",
    "def get_python_list(results):\n",
    "    return eval(results[16:-4])\n",
    "\n",
    "# List of prompts to process in parallel\n",
    "prompts = [prompt] * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 3/200 [00:36<38:29, 11.72s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_results = []\n",
    "previous_keys = []\n",
    "num_p = 10\n",
    "num_iters = 100\n",
    "for i in tqdm(range(num_iters), total=num_iters):\n",
    "    if(len(previous_keys) > 0):\n",
    "        prompt_new = prompt + \"\\n\\n **DO NOT use topics similar to the following:**\\n\" + \"- \".join(previous_keys[0:10])\n",
    "        prompts = [prompt_new] * num_p\n",
    "    else:\n",
    "        prompts = [prompt] * num_p\n",
    "\n",
    "    # Use ThreadPoolExecutor to send parallel requests\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_p) as executor:\n",
    "        results = list(executor.map(fetch_response, prompts))\n",
    "\n",
    "    # Print the results\n",
    "    previous_keys = []\n",
    "    for i, result in enumerate(results):\n",
    "        try:\n",
    "            result = get_python_list(result)\n",
    "            keys = list(result.keys())\n",
    "            previous_keys += keys\n",
    "            all_results.append([{key: result[key]} for key in keys])\n",
    "        except:\n",
    "            print(f\"Error in processing result {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for result in all_results:\n",
    "    final += result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results\n",
    "with open(\"dataset_updating.json\", \"w\") as f:\n",
    "    json.dump(final, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capital of Spain': [{'timestamp': 'T1',\n",
       "   'attributes': {'Capital': 'Lisbon', 'Famous Landmark': 'Eiffel Tower'},\n",
       "   'qa': {'question': 'What is the capital of Spain?', 'answer': 'Lisbon'}},\n",
       "  {'timestamp': 'T2',\n",
       "   'attributes': {'Famous Landmark': 'Statue of Liberty'},\n",
       "   'qa': {'question': 'What is the capital of Spain and its famous landmark?',\n",
       "    'answer': 'Lisbon, with the famous Statue of Liberty.'}}]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
