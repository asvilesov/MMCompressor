{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 21:04:50.222902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739826290.231135  182475 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739826290.234848  182475 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, AutoModel, AutoImageProcessor\n",
    "\n",
    "model_name = \"DAMO-NLP-SG/VideoLLaMA3-2B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "video_path = \"put your video path here\"\n",
    "image_path = \"put your image path here\"\n",
    "question = \"Describe this video in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's name is Joe Jaramazovic.\n"
     ]
    }
   ],
   "source": [
    "# Video conversation\n",
    "video_path = \"/home/ubuntu/sample.mp4\"\n",
    "#image_path = \"/home/ubuntu/45s.png\"\n",
    "image_path = \"/home/ubuntu/graduation.png\"\n",
    "\n",
    "\n",
    "#sample question\n",
    "#question = \"What happens at time: 10 seconds?\"\n",
    "\n",
    "\n",
    "#image based QA\n",
    "#image_caption = \"A modern educational or institutional building with a green lawn, featuring a white facade and large glass windows under a clear blue sky. A police emblem watermark is visible in the upper right corner\"\n",
    "question = \"What's his name\"\n",
    "\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful and informed assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\", \"video\": {\"video_path\": video_path, \"fps\": 1, \"max_frames\": 1000, \"start_time\":50.0, \"end_time\":70.0}},\n",
    "            {\"type\": \"image\", \"image\": {\"image_path\" : image_path}},\n",
    "            {\"type\": \"text\", \"text\": question},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor(conversation=conversation, return_tensors=\"pt\")\n",
    "inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "if \"pixel_values\" in inputs:\n",
    "    inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.bfloat16)\n",
    "output_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "response = processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sequence length: 7488\n"
     ]
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape\n",
    "token_length = inputs[\"input_ids\"].shape[1]\n",
    "print(f\"Tokenized sequence length: {token_length}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,  ...,    829, 151645,    198]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'),\n",
       " 'pixel_values': tensor([[-0.1455, -0.1455, -0.1377,  ..., -0.4668, -0.4746, -0.4824],\n",
       "         [-0.0747, -0.0747, -0.0747,  ..., -0.2793, -0.2637, -0.2793],\n",
       "         [-0.3730, -0.3809, -0.4043,  ..., -0.3027, -0.3105, -0.3105],\n",
       "         ...,\n",
       "         [-0.6719, -0.6562, -0.6484,  ..., -0.6562, -0.6484, -0.6484],\n",
       "         [-0.6172, -0.6016, -0.5938,  ..., -0.6250, -0.6328, -0.6406],\n",
       "         [-0.6719, -0.6719, -0.6719,  ..., -0.6562, -0.6562, -0.6562]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'grid_sizes': tensor([[20, 26, 46],\n",
       "         [ 1, 45, 29]], device='cuda:0'),\n",
       " 'merge_sizes': tensor([2, 1], device='cuda:0'),\n",
       " 'modals': ['video', 'image']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.forward(**inputs, return_dict=True, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicCache()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 1.6094,  1.1562,  2.6875,  ..., -1.2188, -1.2188, -1.2188],\n",
       "         [ 6.9062,  4.1562,  6.9062,  ..., -0.6875, -0.6875, -0.6875],\n",
       "         [ 4.7812,  6.6250,  9.0000,  ..., -3.6562, -3.6562, -3.6562],\n",
       "         ...,\n",
       "         [12.1250,  8.4375,  6.2188,  ...,  0.4922,  0.4922,  0.4922],\n",
       "         [ 7.0000,  3.6719,  5.3125,  ..., -3.2656, -3.2656, -3.2656],\n",
       "         [ 6.0312,  9.6875,  6.4062,  ..., -2.7500, -2.7500, -2.7500]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6665, 151936])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 6665, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
